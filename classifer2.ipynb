{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing models and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 37 entries, 0 to 36\nData columns (total 12 columns):\n #   Column                                      Non-Null Count  Dtype \n---  ------                                      --------------  ----- \n 0   State                                       37 non-null     object\n 1   Cases pending trial from the previous year  37 non-null     int64 \n 2   Cases sent for trial during the year        37 non-null     int64 \n 3   Total cases for\ntrial during the year       37 non-null     int64 \n 4   Cases withdrawn by the Govt                 37 non-null     int64 \n 5   Cases disposed off by Plea Bargaining       37 non-null     int64 \n 6   Cases compounded or withdrawn               37 non-null     int64 \n 7   Cases in which trials were completed        37 non-null     int64 \n 8   Cases convicted                             37 non-null     int64 \n 9   Cases Acquitted or Discharged               37 non-null     int64 \n 10  Total cases disposed off by courts          37 non-null     int64 \n 11  Cases Pending trial at the end of the year  37 non-null     int64 \ndtypes: int64(11), object(1)\nmemory usage: 3.6+ KB\n"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"state-wise-women2.csv\") \n",
    "df1.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1.iloc[:-1, 1:-1].values\n",
    "y = df1.iloc[:-1, -1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[2155,  937, 3092,    0,    0,   15,  631,   79,  552,  646],\n       [ 706,   63,  769,    0,    0,    2,   24,   14,   10,   26],\n       [7188, 1276, 8464,    0,    0,    0,  636,  103,  533,  636],\n       [4651, 1157, 5808,    0,    0,    0,  390,  146,  244,  390],\n       [2910, 1608, 4518,    0,    0,    0, 1518,  453, 1065, 1518]],\n      dtype=int64)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "x[:5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No need for Encoding and also it has no missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the Data into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[3053, 1311, 4364,    0,    0,    0,  695,   91,  604,  695],\n       [ 127,   23,  150,    0,    0,    0,    7,    0,    7,    7],\n       [ 183,  263,  446,    0,    0,    0,  114,   61,   53,  114],\n       [  20,    4,   24,    0,    0,    0,    2,    1,    1,    2],\n       [5011, 2109, 7120,    0,    0,    0,  586,  156,  430,  586]],\n      dtype=int64)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "xtrain[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feaure Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler() \n",
    "xtrain = sc.fit_transform(xtrain) \n",
    "xtest = sc.transform(xtest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[-0.15879382,  0.17767275, -0.09331669,  0.        , -0.19245009,\n        -0.48709524,  0.13062339, -0.25467279,  0.28114066,  0.11830934],\n       [-0.75997961, -0.84819821, -0.80857089,  0.        , -0.19245009,\n        -0.48709524, -0.75447295, -0.65107247, -0.76786542, -0.75726161],\n       [-0.74847366, -0.65704213, -0.75832997,  0.        , -0.19245009,\n        -0.48709524, -0.61681989, -0.385354  , -0.68703748, -0.62108997],\n       [-0.78196419, -0.8633314 , -0.82995723,  0.        , -0.19245009,\n        -0.48709524, -0.76090534, -0.64671643, -0.77840819, -0.76362477],\n       [ 0.24350343,  0.81326671,  0.37446702,  0.        , -0.19245009,\n        -0.48709524, -0.00960263,  0.02846984, -0.02459981, -0.02040757]])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "xtrain[:5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training various ML Models over same training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(random_state=0)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "lrc = LogisticRegression(random_state=0)\n",
    "lrc.fit(xtrain, ytrain)\n",
    "knnc = KNeighborsClassifier() \n",
    "knnc.fit(xtrain, ytrain) \n",
    "dtc = DecisionTreeClassifier() \n",
    "dtc.fit(xtrain, ytrain) \n",
    "svc = SVC(kernel=\"rbf\", random_state=0) \n",
    "svc.fit(xtrain, ytrain) \n",
    "nbc = GaussianNB() \n",
    "nbc.fit(xtrain, ytrain) \n",
    "rfc = RandomForestClassifier(random_state=0) \n",
    "rfc.fit(xtrain, ytrain) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Test Results and Observing Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Logestic Regressor \n",
    "lrpred = lrc.predict(xtest) \n",
    "confusion_matrix(ytest, lrpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# K-NearestNeighbour \n",
    "knnpred = knnc.predict(xtest) \n",
    "confusion_matrix(ytest, knnpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Decision Tree Classifier \n",
    "dtpred = dtc.predict(xtest) \n",
    "confusion_matrix(ytest, dtpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Support Vector Machines \n",
    "svmpred = svc.predict(xtest)\n",
    "confusion_matrix(ytest, svmpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Naive Bayes \n",
    "nbpred = nbc.predict(xtest) \n",
    "confusion_matrix(ytest, nbpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Random Forest \n",
    "rfpred = rfc.predict(xtest) \n",
    "confusion_matrix(ytest, rfpred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "# Logestic Regressor \n",
    "accuracy_score(ytest, lrpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# K-NearestNeighbour \n",
    "accuracy_score(ytest, knnpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Decision Tree Classifier \n",
    "accuracy_score(ytest, dtpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Support Vector Machines \n",
    "accuracy_score(ytest, svmpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Naive Bayes \n",
    "accuracy_score(ytest, nbpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Random Forest \n",
    "accuracy_score(ytest, rfpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score \n",
    "\n",
    "# Logestic Regressor \n",
    "balanced_accuracy_score(ytest, lrpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# K-NearestNeighbour \n",
    "balanced_accuracy_score(ytest, knnpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# Decision Tree Classifier \n",
    "balanced_accuracy_score(ytest, dtpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# Support Vector Machines \n",
    "balanced_accuracy_score(ytest, svmpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# Naive Bayes \n",
    "balanced_accuracy_score(ytest, nbpred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# Random Forest \n",
    "balanced_accuracy_score(ytest, rfpred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of the Project"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitvenvvenv1a367700542447c18d26d2d447f66945",
   "display_name": "Python 3.8.3 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}